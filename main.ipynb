{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96456ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# MAINTENANCE PRÉDICTIVE - FRAMEWORK TESLA\n",
    "# Description : Prédiction de durée de vie des moteurs turbofan\n",
    "# Approche : Analyse multi-dimensionnelle inspirée de Tesla\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import warnings\n",
    "import os\n",
    "import joblib\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration\n",
    "RANDOM_SEED = 42\n",
    "DATA_DIR = 'data'\n",
    "MODEL_DIR = 'models'\n",
    "VIZ_DIR = 'visualizations'\n",
    "\n",
    "print(\"Maintenance Prédictive - Framework Tesla\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "\n",
    "# INITIALISATION\n",
    "\n",
    "\n",
    "def create_directories():\n",
    "    \"\"\"Crée la structure de dossiers du projet\"\"\"\n",
    "    for directory in [DATA_DIR, MODEL_DIR, VIZ_DIR]:\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "    print(\"Structure du projet initialisée\")\n",
    "\n",
    "\n",
    "# ÉTAPE 1 : GÉNÉRATION DES DONNÉES\n",
    "\n",
    "\n",
    "def create_turbofan_data(n_engines=50, save_data=True):\n",
    "    \"\"\"\n",
    "    Génère des données synthétiques de dégradation de moteurs turbofan.\n",
    "    \n",
    "    Basé sur le framework Tesla à 4 dimensions :\n",
    "    - Énergie : température du système\n",
    "    - Vibration : signature mécanique  \n",
    "    - Force : pression interne\n",
    "    - Information : efficacité globale\n",
    "    \"\"\"\n",
    "    print(\"\\nGénération des données moteurs\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    np.random.seed(RANDOM_SEED)\n",
    "    data = []\n",
    "    \n",
    "    for engine_id in range(1, n_engines + 1):\n",
    "        # Chaque moteur a une durée de vie différente\n",
    "        max_cycles = np.random.randint(150, 250)\n",
    "        \n",
    "        for cycle in range(1, max_cycles + 1):\n",
    "            # Modélisation de la dégradation progressive\n",
    "            degradation = (cycle / max_cycles) ** 2\n",
    "            noise_level = 0.1 + degradation * 0.2\n",
    "            \n",
    "            # Les 4 dimensions du framework Tesla\n",
    "            temperature = 500 + degradation * 200 + np.random.normal(0, noise_level * 20)\n",
    "            vibration = 0.5 + degradation * 1.5 + np.random.normal(0, noise_level * 0.3)\n",
    "            pressure = 40 - degradation * 15 + np.random.normal(0, noise_level * 2)\n",
    "            efficiency = 0.9 - degradation * 0.2 + np.random.normal(0, noise_level * 0.05)\n",
    "            \n",
    "            # Durée de vie restante\n",
    "            remaining_useful_life = max_cycles - cycle\n",
    "            \n",
    "            data.append({\n",
    "                'engine_id': engine_id,\n",
    "                'cycle': cycle,\n",
    "                'temperature': max(300, temperature),\n",
    "                'vibration': max(0.1, vibration),\n",
    "                'pressure': max(10, pressure),\n",
    "                'efficiency': max(0.3, min(1.0, efficiency)),\n",
    "                'remaining_useful_life': remaining_useful_life,\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    print(f\"Dataset créé : {len(df):,} échantillons\")\n",
    "    print(f\"Nombre de moteurs : {n_engines}\")\n",
    "    print(f\"RUL moyen : {df['remaining_useful_life'].mean():.1f} cycles\")\n",
    "    \n",
    "    if save_data:\n",
    "        filepath = os.path.join(DATA_DIR, 'turbofan_data.csv')\n",
    "        df.to_csv(filepath, index=False)\n",
    "        print(f\"Données sauvegardées dans : {filepath}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# ÉTAPE 2 : EXPLORATION DES DONNÉES\n",
    "\n",
    "\n",
    "def explore_data(df):\n",
    "    \"\"\"\n",
    "    Analyse exploratoire des données avec focus sur les corrélations\n",
    "    entre les 4 dimensions et la durée de vie restante\n",
    "    \"\"\"\n",
    "    print(\"\\nExploration des données\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Statistiques générales\n",
    "    print(f\"Shape : {df.shape}\")\n",
    "    print(f\"Moteurs uniques : {df['engine_id'].nunique()}\")\n",
    "    \n",
    "    # Analyse RUL\n",
    "    rul = df['remaining_useful_life']\n",
    "    print(f\"\\nStatistiques RUL :\")\n",
    "    print(f\"  Moyenne : {rul.mean():.1f} cycles\")\n",
    "    print(f\"  Médiane : {rul.median():.1f} cycles\")\n",
    "    print(f\"  Min-Max : {rul.min()}-{rul.max()} cycles\")\n",
    "    \n",
    "    # Corrélations avec RUL\n",
    "    sensors = ['temperature', 'vibration', 'pressure', 'efficiency']\n",
    "    correlations = df[sensors + ['remaining_useful_life']].corr()['remaining_useful_life']\n",
    "    \n",
    "    print(f\"\\nCorrélations avec RUL :\")\n",
    "    for sensor in sensors:\n",
    "        corr = correlations[sensor]\n",
    "        print(f\"  {sensor.capitalize()} : {corr:.3f}\")\n",
    "    \n",
    "    return correlations\n",
    "\n",
    "\n",
    "# ÉTAPE 3 : VISUALISATIONS\n",
    "\n",
    "\n",
    "def create_visualizations(df, save_plots=True):\n",
    "    \"\"\"\n",
    "    Crée et sauvegarde les visualisations principales du projet\n",
    "    \"\"\"\n",
    "    print(\"\\nCréation des visualisations\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    plt.style.use('seaborn-v0_8-darkgrid')\n",
    "    \n",
    "    # Figure 1 : Vue d'ensemble 2x2\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    fig.suptitle(\"Analyse Multi-Dimensionnelle des Moteurs Turbofan\", fontsize=14)\n",
    "    \n",
    "    # Distribution RUL\n",
    "    axes[0,0].hist(df['remaining_useful_life'], bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    axes[0,0].set_title('Distribution de la Durée de Vie Restante')\n",
    "    axes[0,0].set_xlabel('RUL (cycles)')\n",
    "    axes[0,0].set_ylabel('Fréquence')\n",
    "    \n",
    "    # Évolution température\n",
    "    sample_engines = df['engine_id'].unique()[:5]\n",
    "    for engine in sample_engines:\n",
    "        engine_data = df[df['engine_id'] == engine]\n",
    "        axes[0,1].plot(engine_data['cycle'], engine_data['temperature'], \n",
    "                        alpha=0.7, label=f'Moteur {engine}')\n",
    "    axes[0,1].set_title('Évolution de la Température')\n",
    "    axes[0,1].set_xlabel('Cycle')\n",
    "    axes[0,1].set_ylabel('Température (°C)')\n",
    "    axes[0,1].legend()\n",
    "    \n",
    "    # Scatter température vs RUL\n",
    "    axes[1,0].scatter(df['temperature'], df['remaining_useful_life'], \n",
    "                        alpha=0.5, c=df['cycle'], cmap='viridis', s=20)\n",
    "    axes[1,0].set_title('Température vs RUL')\n",
    "    axes[1,0].set_xlabel('Température (°C)')\n",
    "    axes[1,0].set_ylabel('RUL (cycles)')\n",
    "    \n",
    "    # Matrice de corrélation\n",
    "    sensors = ['temperature', 'vibration', 'pressure', 'efficiency']\n",
    "    corr_matrix = df[sensors].corr()\n",
    "    sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "                center=0, square=True, ax=axes[1,1])\n",
    "    axes[1,1].set_title('Corrélations entre Capteurs')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_plots:\n",
    "        plt.savefig(os.path.join(VIZ_DIR, 'analysis_overview.png'), dpi=150, bbox_inches='tight')\n",
    "        print(\"Visualisations sauvegardées dans le dossier visualizations/\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ÉTAPE 4 : ENTRAÎNEMENT DU MODÈLE\n",
    "\n",
    "\n",
    "def train_model(df, save_model=True):\n",
    "    \"\"\"\n",
    "    Entraîne un modèle Random Forest pour prédire la durée de vie restante\n",
    "    \"\"\"\n",
    "    print(\"\\nEntraînement du modèle\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Préparation des données\n",
    "    features = ['temperature', 'vibration', 'pressure', 'efficiency']\n",
    "    X = df[features]\n",
    "    y = df['remaining_useful_life']\n",
    "    \n",
    "    # Division train/test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=RANDOM_SEED\n",
    "    )\n",
    "    \n",
    "    print(f\"Données d'entraînement : {len(X_train)} échantillons\")\n",
    "    print(f\"Données de test : {len(X_test)} échantillons\")\n",
    "    \n",
    "    # Configuration et entraînement du modèle\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=15,\n",
    "        min_samples_split=5,\n",
    "        random_state=RANDOM_SEED,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    print(\"Entraînement en cours...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Évaluation\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    print(f\"\\nPerformances du modèle :\")\n",
    "    print(f\"  MAE (train) : {train_mae:.2f} cycles\")\n",
    "    print(f\"  MAE (test)  : {test_mae:.2f} cycles\")\n",
    "    print(f\"  R² (train)  : {train_r2:.3f}\")\n",
    "    print(f\"  R² (test)   : {test_r2:.3f}\")\n",
    "    \n",
    "    # Vérification overfitting\n",
    "    if test_mae > train_mae * 1.5:\n",
    "        print(\"\\nAttention : Possible surapprentissage détecté\")\n",
    "    else:\n",
    "        print(\"\\nPas de surapprentissage significatif\")\n",
    "    \n",
    "    # Importance des features\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': features,\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(f\"\\nImportance des variables :\")\n",
    "    for _, row in importance_df.iterrows():\n",
    "        print(f\"  {row['feature']} : {row['importance']:.3f}\")\n",
    "    \n",
    "    if save_model:\n",
    "        model_path = os.path.join(MODEL_DIR, 'random_forest_model.pkl')\n",
    "        joblib.dump(model, model_path)\n",
    "        print(f\"\\nModèle sauvegardé dans {model_path}\")\n",
    "        \n",
    "        # Sauvegarde des métriques\n",
    "        metrics = {\n",
    "            'train_mae': float(train_mae),\n",
    "            'test_mae': float(test_mae),\n",
    "            'train_r2': float(train_r2),\n",
    "            'test_r2': float(test_r2),\n",
    "            'feature_importance': importance_df.to_dict('records'),\n",
    "            'training_date': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        }\n",
    "        \n",
    "        metrics_path = os.path.join(MODEL_DIR, 'model_metrics.json')\n",
    "        with open(metrics_path, 'w') as f:\n",
    "            json.dump(metrics, f, indent=2)\n",
    "    \n",
    "    return model, X_test, y_test, y_test_pred, test_mae, test_r2\n",
    "\n",
    "\n",
    "# ÉTAPE 5 : ANALYSE DES RÉSULTATS\n",
    "\n",
    "\n",
    "def analyze_predictions(y_test, y_pred, save_plots=True):\n",
    "    \"\"\"\n",
    "    Analyse détaillée des prédictions du modèle\n",
    "    \"\"\"\n",
    "    print(\"\\nAnalyse des prédictions\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Calcul des erreurs\n",
    "    errors = y_test - y_pred\n",
    "    abs_errors = np.abs(errors)\n",
    "    \n",
    "    print(f\"Erreur moyenne : {np.mean(errors):.2f} cycles\")\n",
    "    print(f\"Erreur médiane : {np.median(errors):.2f} cycles\")\n",
    "    print(f\"Erreur maximale : {np.max(abs_errors):.2f} cycles\")\n",
    "    \n",
    "    # Visualisation\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # Prédictions vs Réalité\n",
    "    ax1.scatter(y_test, y_pred, alpha=0.6, color='blue', edgecolor='black', linewidth=0.5)\n",
    "    ax1.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \n",
    "                'r--', lw=2, label='Prédiction parfaite')\n",
    "    ax1.set_xlabel('RUL Réel (cycles)')\n",
    "    ax1.set_ylabel('RUL Prédit (cycles)')\n",
    "    ax1.set_title('Prédictions vs Réalité')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Distribution des erreurs\n",
    "    ax2.hist(errors, bins=30, alpha=0.7, color='green', edgecolor='black')\n",
    "    ax2.axvline(0, color='red', linestyle='dashed', linewidth=2)\n",
    "    ax2.set_xlabel('Erreur de prédiction (cycles)')\n",
    "    ax2.set_ylabel('Fréquence')\n",
    "    ax2.set_title('Distribution des Erreurs')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_plots:\n",
    "        plt.savefig(os.path.join(VIZ_DIR, 'prediction_analysis.png'), dpi=150, bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# FONCTION PRINCIPALE\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Pipeline complet d'analyse prédictive\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"PROJET MAINTENANCE PRÉDICTIVE - FRAMEWORK TESLA\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"Objectif : Prédire la durée de vie des moteurs turbofan\")\n",
    "    print(\"Approche : Analyse multi-dimensionnelle (Tesla)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    try:\n",
    "        # Initialisation\n",
    "        create_directories()\n",
    "        \n",
    "        # 1. Génération des données\n",
    "        df = create_turbofan_data(n_engines=50)\n",
    "        \n",
    "        # 2. Exploration\n",
    "        correlations = explore_data(df)\n",
    "        \n",
    "        # 3. Visualisations\n",
    "        create_visualizations(df)\n",
    "        \n",
    "        # 4. Machine Learning\n",
    "        model, X_test, y_test, y_pred, test_mae, test_r2 = train_model(df)\n",
    "        \n",
    "        # 5. Analyse des résultats\n",
    "        analyze_predictions(y_test, y_pred)\n",
    "        \n",
    "        # Résumé final\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"RÉSUMÉ DU PROJET\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Modèle entraîné avec succès\")\n",
    "        print(f\"Performance : MAE = {test_mae:.1f} cycles, R² = {test_r2:.3f}\")\n",
    "        print(f\"Le modèle peut prédire les pannes environ {test_mae:.0f} cycles à l'avance\")\n",
    "        print(\"\\nFichiers générés :\")\n",
    "        print(\"  - data/turbofan_data.csv\")\n",
    "        print(\"  - models/random_forest_model.pkl\")\n",
    "        print(\"  - visualizations/*.png\")\n",
    "        \n",
    "        return df, model\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de l'exécution : {e}\")\n",
    "        return None, None\n",
    "\n",
    "\n",
    "# EXÉCUTION\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data, model = main()\n",
    "    \n",
    "    print(\"\\nProchaines étapes:\")\n",
    "    print(\" Tester avec des données réelles (NASA C-MAPSS)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
